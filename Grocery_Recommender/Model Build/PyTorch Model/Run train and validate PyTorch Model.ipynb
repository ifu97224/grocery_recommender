{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the features to use for modeling\n",
    "\n",
    "feat_list = [\n",
    "    \"CUST_PRICE_SENSITIVITY\",\n",
    "    \"CUST_LIFESTAGE\",\n",
    "    \"BASKET_SIZE_PROP_SPEND_PROD_CODE_M\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_LA\",\n",
    "    \"DAY_PART_PROP_SPEND_CUST_CODE_AFTERNOON\",\n",
    "    \"BASKET_SIZE_PROP_VISITS_CUST_CODE_L\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Fresh\",\n",
    "    \"BASKET_TYPE_PROP_VISITS_CUST_CODE_Small Shop\",\n",
    "    \"BASKET_SIZE_PROP_QUANTITY_PROD_CODE_L\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_CUST_CODE_MS\",\n",
    "    \"CHNG_VISITS_PROD_CODE_30_1_52\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_PROD_CODE_LS\",\n",
    "    \"STORE_FORMAT_PROP_QUANTITY_CUST_CODE_SS\",\n",
    "    \"BASKET_SIZE_QUANTITY_CUST_CODE_S\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_QUANTITY_PROD_CODE_Nonfood\",\n",
    "    \"CHNG_SPEND_PROD_CODE_40_8_52\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_VISITS_CUST_CODE_XX\",\n",
    "    \"BASKET_TYPE_VISITS_CUST_CODE_XX\",\n",
    "    \"WKDAY_WKEND_PROP_QUANTITY_CUST_CODE_WEEKEND\",\n",
    "    \"BASKET_TYPE_QUANTITY_CUST_CODE_Small Shop\",\n",
    "    \"SPEND_PROD_CODE_30_52\",\n",
    "    \"BASKET_TYPE_SPEND_CUST_CODE_Top Up\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_CUST_CODE_Grocery\",\n",
    "    \"CHNG_QUANTITY_PROD_CODE_40_26_52\",\n",
    "    \"SPEND_PROD_CODE_20_52\",\n",
    "    \"BASKET_TYPE_PROP_QUANTITY_CUST_CODE_Top Up\",\n",
    "    \"VISITS_PROD_CODE_20_52\",\n",
    "    \"WKDAY_WKEND_PROP_VISITS_PROD_CODE_WEEKEND\",\n",
    "    \"VISITS_PROD_CODE_40_1\",\n",
    "    \"CHNG_VISITS_PROD_CODE_40_1_26\",\n",
    "    \"BASKET_TYPE_PROP_SPEND_PROD_CODE_XX\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_CUST_CODE_XLS\",\n",
    "    \"DAY_PART_PROP_VISITS_CUST_CODE_EVENING\",\n",
    "    \"TIME_BTWN_MEDIAN_OVERALL_PROD_CODE_40\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_PROD_CODE_XLS\",\n",
    "    \"DAY_PART_PROP_SPEND_PROD_CODE_MORNING\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_PROD_CODE_SS\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_PROD_CODE_MS\",\n",
    "    \"DAY_PART_PROP_SPEND_CUST_CODE_MORNING\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_SPEND_PROD_CODE_LA\",\n",
    "    \"DAY_PART_PROP_QUANTITY_PROD_CODE_EVENING\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_UM\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Grocery\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_PROD_CODE_MM\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_CUST_CODE_LS\",\n",
    "    \"QUANTITY_PROD_CODE_52\",\n",
    "    \"BASKET_TYPE_PROP_VISITS_PROD_CODE_Top Up\",\n",
    "    \"DAY_PART_PROP_SPEND_PROD_CODE_AFTERNOON\",\n",
    "    \"CHNG_VISITS_PROD_CODE_20_1_8\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_CUST_CODE_MM\",\n",
    "    \"BASKET_DOMINANT_MISSION_SPEND_CUST_CODE_XX\",\n",
    "    \"USER_factor_0\",\n",
    "    \"USER_factor_1\",\n",
    "    \"USER_factor_2\",\n",
    "    \"USER_factor_3\",\n",
    "    \"USER_factor_4\",\n",
    "    \"ITEM_factor_0\",\n",
    "    \"ITEM_factor_1\",\n",
    "    \"ITEM_factor_2\",\n",
    "    \"ITEM_factor_3\",\n",
    "    \"ITEM_factor_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sklearn_v,\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the specified features from the training and test sets that will be used for model developement\n",
    "input_data_train, input_data_test = tf_model_input_prep.create_model_input(\n",
    "    bucket=\"udacity-machine-learning-capstone-data\",\n",
    "    train_key=\"train_df_features.csv\",\n",
    "    test_key=\"test_df_features.csv\",\n",
    "    out_file_train=\"train_df_final_features.csv\",\n",
    "    out_file_test=\"test_df_final_features.csv\",\n",
    "    feat_list=feat_list,\n",
    ")\n",
    "\n",
    "# Run the pre-processing steps by calling preprocessing.py\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocessing_tf_model.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data_train, destination=\"/opt/ml/processing/input_data_train\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=input_data_test, destination=\"/opt/ml/processing/input_data_test\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n",
    "        ProcessingOutput(output_name=\"valid_data\", source=\"/opt/ml/processing/valid\"),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train_data\":\n",
    "        preprocessed_training_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"test_data\":\n",
    "        preprocessed_test_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"valid_data\":\n",
    "        preprocessed_valid_data = output[\"S3Output\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# your import and estimator code, here\n",
    "\n",
    "# specify an output path\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source_pytorch', # this should be just \"source\" for your code\n",
    "                    role=role,\n",
    "                    framework_version='1.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'input_features': 3,  # num of features\n",
    "                        'hidden_dim': 10,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 1000 # could change to higher\n",
    "                    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
