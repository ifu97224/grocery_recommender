{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run, train and validate DNN (PyTorch Model)\n",
    "\n",
    "Pre-process the data, train and validate models using AUC as the performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    ContinuousParameter,\n",
    "    CategoricalParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "sklearn_v = \"0.20.0\"\n",
    "\n",
    "import SKLearn_input_prep\n",
    "import plot_hyperparameter_tuning as plt_hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the features to use for modeling\n",
    "\n",
    "feat_list = [\n",
    "    \"CUST_PRICE_SENSITIVITY\",\n",
    "    \"CUST_LIFESTAGE\",\n",
    "    \"BASKET_SIZE_PROP_SPEND_PROD_CODE_M\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_LA\",\n",
    "    \"DAY_PART_PROP_SPEND_CUST_CODE_AFTERNOON\",\n",
    "    \"BASKET_SIZE_PROP_VISITS_CUST_CODE_L\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Fresh\",\n",
    "    \"BASKET_TYPE_PROP_VISITS_CUST_CODE_Small Shop\",\n",
    "    \"BASKET_SIZE_PROP_QUANTITY_PROD_CODE_L\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_CUST_CODE_MS\",\n",
    "    \"CHNG_VISITS_PROD_CODE_30_1_52\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_PROD_CODE_LS\",\n",
    "    \"STORE_FORMAT_PROP_QUANTITY_CUST_CODE_SS\",\n",
    "    \"BASKET_SIZE_QUANTITY_CUST_CODE_S\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_QUANTITY_PROD_CODE_Nonfood\",\n",
    "    \"CHNG_SPEND_PROD_CODE_40_8_52\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_VISITS_CUST_CODE_XX\",\n",
    "    \"BASKET_TYPE_VISITS_CUST_CODE_XX\",\n",
    "    \"WKDAY_WKEND_PROP_QUANTITY_CUST_CODE_WEEKEND\",\n",
    "    \"BASKET_TYPE_QUANTITY_CUST_CODE_Small Shop\",\n",
    "    \"SPEND_PROD_CODE_30_52\",\n",
    "    \"BASKET_TYPE_SPEND_CUST_CODE_Top Up\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_CUST_CODE_Grocery\",\n",
    "    \"CHNG_QUANTITY_PROD_CODE_40_26_52\",\n",
    "    \"SPEND_PROD_CODE_20_52\",\n",
    "    \"BASKET_TYPE_PROP_QUANTITY_CUST_CODE_Top Up\",\n",
    "    \"VISITS_PROD_CODE_20_52\",\n",
    "    \"WKDAY_WKEND_PROP_VISITS_PROD_CODE_WEEKEND\",\n",
    "    \"VISITS_PROD_CODE_40_1\",\n",
    "    \"CHNG_VISITS_PROD_CODE_40_1_26\",\n",
    "    \"BASKET_TYPE_PROP_SPEND_PROD_CODE_XX\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_CUST_CODE_XLS\",\n",
    "    \"DAY_PART_PROP_VISITS_CUST_CODE_EVENING\",\n",
    "    \"TIME_BTWN_MEDIAN_OVERALL_PROD_CODE_40\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_PROD_CODE_XLS\",\n",
    "    \"DAY_PART_PROP_SPEND_PROD_CODE_MORNING\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_PROD_CODE_SS\",\n",
    "    \"STORE_FORMAT_PROP_VISITS_PROD_CODE_MS\",\n",
    "    \"DAY_PART_PROP_SPEND_CUST_CODE_MORNING\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_SPEND_PROD_CODE_LA\",\n",
    "    \"DAY_PART_PROP_QUANTITY_PROD_CODE_EVENING\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_UM\",\n",
    "    \"BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Grocery\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_PROD_CODE_MM\",\n",
    "    \"STORE_FORMAT_PROP_SPEND_CUST_CODE_LS\",\n",
    "    \"QUANTITY_PROD_CODE_52\",\n",
    "    \"BASKET_TYPE_PROP_VISITS_PROD_CODE_Top Up\",\n",
    "    \"DAY_PART_PROP_SPEND_PROD_CODE_AFTERNOON\",\n",
    "    \"CHNG_VISITS_PROD_CODE_20_1_8\",\n",
    "    \"BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_CUST_CODE_MM\",\n",
    "    \"BASKET_DOMINANT_MISSION_SPEND_CUST_CODE_XX\",\n",
    "    \"USER_factor_0\",\n",
    "    \"USER_factor_1\",\n",
    "    \"USER_factor_2\",\n",
    "    \"USER_factor_3\",\n",
    "    \"USER_factor_4\",\n",
    "    \"ITEM_factor_0\",\n",
    "    \"ITEM_factor_1\",\n",
    "    \"ITEM_factor_2\",\n",
    "    \"ITEM_factor_3\",\n",
    "    \"ITEM_factor_4\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sklearn_v,\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-03-14-21-27-12-122\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://udacity-machine-learning-capstone-data/train_df_final_features.csv', 'LocalPath': '/opt/ml/processing/input_data_train', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'S3Input': {'S3Uri': 's3://udacity-machine-learning-capstone-data/test_df_final_features.csv', 'LocalPath': '/opt/ml/processing/input_data_test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-800613416076/sagemaker-scikit-learn-2020-03-14-21-27-12-122/input/code/preprocessing_pytorch_model.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-800613416076/sagemaker-scikit-learn-2020-03-14-21-27-12-122/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-800613416076/sagemaker-scikit-learn-2020-03-14-21-27-12-122/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'valid_data', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-2-800613416076/sagemaker-scikit-learn-2020-03-14-21-27-12-122/output/valid_data', 'LocalPath': '/opt/ml/processing/valid', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...................\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mReceived arguments Namespace(train_test_split_ratio=0.2)\u001b[0m\n",
      "\u001b[34mReading input training data from /opt/ml/processing/input_data_train/train_df_final_features.csv\u001b[0m\n",
      "\u001b[34mReading input test data from /opt/ml/processing/input_data_test/test_df_final_features.csv\u001b[0m\n",
      "\u001b[34mFurther splitting the training data into train and test sets with ratio 0.2\u001b[0m\n",
      "\u001b[34mTrain data contains: (23278, 62) observations of which 11622 are positive examples and 11656 are negative examples\u001b[0m\n",
      "\u001b[34mTest data contains: (5820, 62) observations of which 2929 are positive examples and 2891 are negative examples\u001b[0m\n",
      "\u001b[34mValidation data contains: (29098, 62) observations of which 14551 are positive examples and 14547 are negative examples\u001b[0m\n",
      "\u001b[34mCategorical features ['CUST_PRICE_SENSITIVITY', 'CUST_LIFESTAGE']\u001b[0m\n",
      "\u001b[34mNumeric features ['BASKET_SIZE_PROP_SPEND_PROD_CODE_M', 'BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_LA', 'DAY_PART_PROP_SPEND_CUST_CODE_AFTERNOON', 'BASKET_SIZE_PROP_VISITS_CUST_CODE_L', 'BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Fresh', 'BASKET_TYPE_PROP_VISITS_CUST_CODE_Small Shop', 'BASKET_SIZE_PROP_QUANTITY_PROD_CODE_L', 'STORE_FORMAT_PROP_VISITS_CUST_CODE_MS', 'CHNG_VISITS_PROD_CODE_30_1_52', 'STORE_FORMAT_PROP_SPEND_PROD_CODE_LS', 'STORE_FORMAT_PROP_QUANTITY_CUST_CODE_SS', 'BASKET_SIZE_QUANTITY_CUST_CODE_S', 'BASKET_DOMINANT_MISSION_PROP_QUANTITY_PROD_CODE_Nonfood', 'CHNG_SPEND_PROD_CODE_40_8_52', 'BASKET_DOMINANT_MISSION_PROP_VISITS_CUST_CODE_XX', 'BASKET_TYPE_VISITS_CUST_CODE_XX', 'WKDAY_WKEND_PROP_QUANTITY_CUST_CODE_WEEKEND', 'BASKET_TYPE_QUANTITY_CUST_CODE_Small Shop', 'SPEND_PROD_CODE_30_52', 'BASKET_TYPE_SPEND_CUST_CODE_Top Up', 'BASKET_DOMINANT_MISSION_PROP_SPEND_CUST_CODE_Grocery', 'CHNG_QUANTITY_PROD_CODE_40_26_52', 'SPEND_PROD_CODE_20_52', 'BASKET_TYPE_PROP_QUANTITY_CUST_CODE_Top Up', 'VISITS_PROD_CODE_20_52', 'WKDAY_WKEND_PROP_VISITS_PROD_CODE_WEEKEND', 'VISITS_PROD_CODE_40_1', 'CHNG_VISITS_PROD_CODE_40_1_26', 'BASKET_TYPE_PROP_SPEND_PROD_CODE_XX', 'STORE_FORMAT_PROP_VISITS_CUST_CODE_XLS', 'DAY_PART_PROP_VISITS_CUST_CODE_EVENING', 'TIME_BTWN_MEDIAN_OVERALL_PROD_CODE_40', 'STORE_FORMAT_PROP_VISITS_PROD_CODE_XLS', 'DAY_PART_PROP_SPEND_PROD_CODE_MORNING', 'STORE_FORMAT_PROP_SPEND_PROD_CODE_SS', 'STORE_FORMAT_PROP_VISITS_PROD_CODE_MS', 'DAY_PART_PROP_SPEND_CUST_CODE_MORNING', 'BASKET_PRICE_SENSITIVITY_PROP_SPEND_PROD_CODE_LA', 'DAY_PART_PROP_QUANTITY_PROD_CODE_EVENING', 'BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_UM', 'BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Grocery', 'BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_PROD_CODE_MM', 'STORE_FORMAT_PROP_SPEND_CUST_CODE_LS', 'QUANTITY_PROD_CODE_52', 'BASKET_TYPE_PROP_VISITS_PROD_CODE_Top Up', 'DAY_PART_PROP_SPEND_PROD_CODE_AFTERNOON', 'CHNG_VISITS_PROD_CODE_20_1_8', 'BASKET_PRICE_SENSITIVITY_PROP_QUANTITY_CUST_CODE_MM', 'BASKET_DOMINANT_MISSION_SPEND_CUST_CODE_XX', 'USER_factor_0', 'USER_factor_1', 'USER_factor_2', 'USER_factor_3', 'USER_factor_4', 'ITEM_factor_0', 'ITEM_factor_1', 'ITEM_factor_2', 'ITEM_factor_3', 'ITEM_factor_4']\u001b[0m\n",
      "\u001b[34mStandardizing numeric features\u001b[0m\n",
      "\u001b[34mOne hot encoding categorical features\u001b[0m\n",
      "\u001b[34mTrain data shape after standardizing: (18652, 71)\u001b[0m\n",
      "\u001b[34mTest data shape after standardizing: (1131, 71)\u001b[0m\n",
      "\u001b[34mValidation data shape after standardizing: (23278, 71)\u001b[0m\n",
      "\u001b[34mSaving training DataFrame to /opt/ml/processing/train/train_df.csv\u001b[0m\n",
      "\u001b[34mSaving test DataFrame to /opt/ml/processing/test/test_df.csv\u001b[0m\n",
      "\u001b[34mSaving validation DataFrame to /opt/ml/processing/valid/valid_df.csv\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep only the specified features from the training and test sets that will be used for model developement\n",
    "input_data_train, input_data_test = SKLearn_input_prep.create_model_input(\n",
    "    bucket=\"udacity-machine-learning-capstone-data\",\n",
    "    train_key=\"train_df_features.csv\",\n",
    "    test_key=\"test_df_features.csv\",\n",
    "    out_file_train=\"train_df_final_features.csv\",\n",
    "    out_file_test=\"test_df_final_features.csv\",\n",
    "    feat_list=feat_list,\n",
    ")\n",
    "\n",
    "# Run the pre-processing steps by calling preprocessing.py\n",
    "sklearn_processor.run(\n",
    "    code=\"preprocessing_pytorch_model.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=input_data_train, destination=\"/opt/ml/processing/input_data_train\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=input_data_test, destination=\"/opt/ml/processing/input_data_test\"\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train_data\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"test_data\", source=\"/opt/ml/processing/test\"),\n",
    "        ProcessingOutput(output_name=\"valid_data\", source=\"/opt/ml/processing/valid\"),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    ")\n",
    "\n",
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train_data\":\n",
    "        preprocessed_training_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"test_data\":\n",
    "        preprocessed_test_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    if output[\"OutputName\"] == \"valid_data\":\n",
    "        preprocessed_valid_data = output[\"S3Output\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataFrame shape: (18652, 71)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>BASKET_SIZE_PROP_SPEND_PROD_CODE_M</th>\n",
       "      <th>BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_LA</th>\n",
       "      <th>DAY_PART_PROP_SPEND_CUST_CODE_AFTERNOON</th>\n",
       "      <th>BASKET_SIZE_PROP_VISITS_CUST_CODE_L</th>\n",
       "      <th>BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Fresh</th>\n",
       "      <th>BASKET_TYPE_PROP_VISITS_CUST_CODE_Small Shop</th>\n",
       "      <th>BASKET_SIZE_PROP_QUANTITY_PROD_CODE_L</th>\n",
       "      <th>STORE_FORMAT_PROP_VISITS_CUST_CODE_MS</th>\n",
       "      <th>CHNG_VISITS_PROD_CODE_30_1_52</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_MM</th>\n",
       "      <th>x0_UM</th>\n",
       "      <th>x0_XX</th>\n",
       "      <th>x1_OA</th>\n",
       "      <th>x1_OF</th>\n",
       "      <th>x1_OT</th>\n",
       "      <th>x1_PE</th>\n",
       "      <th>x1_XX</th>\n",
       "      <th>x1_YA</th>\n",
       "      <th>x1_YF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.126890</td>\n",
       "      <td>-0.376453</td>\n",
       "      <td>-1.378870</td>\n",
       "      <td>1.082173</td>\n",
       "      <td>-0.810606</td>\n",
       "      <td>-0.806275</td>\n",
       "      <td>-2.572434</td>\n",
       "      <td>-0.561918</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137103</td>\n",
       "      <td>-0.094667</td>\n",
       "      <td>0.337954</td>\n",
       "      <td>-0.203006</td>\n",
       "      <td>0.469229</td>\n",
       "      <td>0.089560</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.912198</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059633</td>\n",
       "      <td>-0.325516</td>\n",
       "      <td>0.982212</td>\n",
       "      <td>0.851148</td>\n",
       "      <td>0.315727</td>\n",
       "      <td>-0.582191</td>\n",
       "      <td>-0.160575</td>\n",
       "      <td>-0.402554</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.126890</td>\n",
       "      <td>0.274827</td>\n",
       "      <td>0.771434</td>\n",
       "      <td>-0.304365</td>\n",
       "      <td>1.851930</td>\n",
       "      <td>0.517465</td>\n",
       "      <td>-2.572434</td>\n",
       "      <td>-0.519190</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.846573</td>\n",
       "      <td>1.155495</td>\n",
       "      <td>-0.431237</td>\n",
       "      <td>1.410940</td>\n",
       "      <td>0.471356</td>\n",
       "      <td>-1.078115</td>\n",
       "      <td>-0.970354</td>\n",
       "      <td>2.386313</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.561912</td>\n",
       "      <td>-0.045304</td>\n",
       "      <td>0.143303</td>\n",
       "      <td>-0.418907</td>\n",
       "      <td>0.523798</td>\n",
       "      <td>0.853377</td>\n",
       "      <td>0.704548</td>\n",
       "      <td>2.347521</td>\n",
       "      <td>0.331831</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.003824</td>\n",
       "      <td>-0.249166</td>\n",
       "      <td>0.449536</td>\n",
       "      <td>-0.409922</td>\n",
       "      <td>-1.698119</td>\n",
       "      <td>0.897950</td>\n",
       "      <td>1.032246</td>\n",
       "      <td>1.479165</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.222099</td>\n",
       "      <td>-0.404790</td>\n",
       "      <td>-1.321283</td>\n",
       "      <td>-1.547961</td>\n",
       "      <td>0.524589</td>\n",
       "      <td>1.857753</td>\n",
       "      <td>-0.036398</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.907018</td>\n",
       "      <td>-0.404790</td>\n",
       "      <td>-1.483189</td>\n",
       "      <td>-1.547961</td>\n",
       "      <td>-0.492442</td>\n",
       "      <td>-1.078115</td>\n",
       "      <td>0.964233</td>\n",
       "      <td>-0.561918</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861890</td>\n",
       "      <td>-0.301678</td>\n",
       "      <td>0.596331</td>\n",
       "      <td>1.410940</td>\n",
       "      <td>-0.891289</td>\n",
       "      <td>-1.078115</td>\n",
       "      <td>-0.606245</td>\n",
       "      <td>2.386313</td>\n",
       "      <td>-0.177029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET  BASKET_SIZE_PROP_SPEND_PROD_CODE_M  \\\n",
       "0     1.0                            4.126890   \n",
       "1     0.0                            0.137103   \n",
       "2     0.0                            0.059633   \n",
       "3     1.0                            4.126890   \n",
       "4     1.0                            1.846573   \n",
       "5     0.0                           -0.561912   \n",
       "6     0.0                           -1.003824   \n",
       "7     1.0                            0.222099   \n",
       "8     1.0                           -0.907018   \n",
       "9     1.0                            0.861890   \n",
       "\n",
       "   BASKET_PRICE_SENSITIVITY_SPEND_CUST_CODE_LA  \\\n",
       "0                                    -0.376453   \n",
       "1                                    -0.094667   \n",
       "2                                    -0.325516   \n",
       "3                                     0.274827   \n",
       "4                                     1.155495   \n",
       "5                                    -0.045304   \n",
       "6                                    -0.249166   \n",
       "7                                    -0.404790   \n",
       "8                                    -0.404790   \n",
       "9                                    -0.301678   \n",
       "\n",
       "   DAY_PART_PROP_SPEND_CUST_CODE_AFTERNOON  \\\n",
       "0                                -1.378870   \n",
       "1                                 0.337954   \n",
       "2                                 0.982212   \n",
       "3                                 0.771434   \n",
       "4                                -0.431237   \n",
       "5                                 0.143303   \n",
       "6                                 0.449536   \n",
       "7                                -1.321283   \n",
       "8                                -1.483189   \n",
       "9                                 0.596331   \n",
       "\n",
       "   BASKET_SIZE_PROP_VISITS_CUST_CODE_L  \\\n",
       "0                             1.082173   \n",
       "1                            -0.203006   \n",
       "2                             0.851148   \n",
       "3                            -0.304365   \n",
       "4                             1.410940   \n",
       "5                            -0.418907   \n",
       "6                            -0.409922   \n",
       "7                            -1.547961   \n",
       "8                            -1.547961   \n",
       "9                             1.410940   \n",
       "\n",
       "   BASKET_DOMINANT_MISSION_PROP_SPEND_PROD_CODE_Fresh  \\\n",
       "0                                          -0.810606    \n",
       "1                                           0.469229    \n",
       "2                                           0.315727    \n",
       "3                                           1.851930    \n",
       "4                                           0.471356    \n",
       "5                                           0.523798    \n",
       "6                                          -1.698119    \n",
       "7                                           0.524589    \n",
       "8                                          -0.492442    \n",
       "9                                          -0.891289    \n",
       "\n",
       "   BASKET_TYPE_PROP_VISITS_CUST_CODE_Small Shop  \\\n",
       "0                                     -0.806275   \n",
       "1                                      0.089560   \n",
       "2                                     -0.582191   \n",
       "3                                      0.517465   \n",
       "4                                     -1.078115   \n",
       "5                                      0.853377   \n",
       "6                                      0.897950   \n",
       "7                                      1.857753   \n",
       "8                                     -1.078115   \n",
       "9                                     -1.078115   \n",
       "\n",
       "   BASKET_SIZE_PROP_QUANTITY_PROD_CODE_L  \\\n",
       "0                              -2.572434   \n",
       "1                               0.021770   \n",
       "2                              -0.160575   \n",
       "3                              -2.572434   \n",
       "4                              -0.970354   \n",
       "5                               0.704548   \n",
       "6                               1.032246   \n",
       "7                              -0.036398   \n",
       "8                               0.964233   \n",
       "9                              -0.606245   \n",
       "\n",
       "   STORE_FORMAT_PROP_VISITS_CUST_CODE_MS  CHNG_VISITS_PROD_CODE_30_1_52  ...  \\\n",
       "0                              -0.561918                      -0.177029  ...   \n",
       "1                               0.912198                      -0.177029  ...   \n",
       "2                              -0.402554                      -0.177029  ...   \n",
       "3                              -0.519190                      -0.177029  ...   \n",
       "4                               2.386313                      -0.177029  ...   \n",
       "5                               2.347521                       0.331831  ...   \n",
       "6                               1.479165                      -0.177029  ...   \n",
       "7                               0.027728                      -0.177029  ...   \n",
       "8                              -0.561918                      -0.177029  ...   \n",
       "9                               2.386313                      -0.177029  ...   \n",
       "\n",
       "   x0_MM  x0_UM  x0_XX  x1_OA  x1_OF  x1_OT  x1_PE  x1_XX  x1_YA  x1_YF  \n",
       "0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "2    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    1.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "5    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "6    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "7    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0  \n",
       "8    0.0    0.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0  \n",
       "9    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10 rows x 71 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(preprocessed_training_data + \"/train_df.csv\")\n",
    "print(\"Training DataFrame shape: {}\".format(train_df.shape))\n",
    "train_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, tune and evaluate DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "# get the number of input features\n",
    "input_features = train_df.shape[1] - 1\n",
    "\n",
    "# get the test set batch size (whole dataset)\n",
    "test_df = pd.read_csv(preprocessed_test_data + \"/test_df.csv\")\n",
    "test_batch_size = test_df.shape[0]\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"source_pytorch\",\n",
    "    role=role,\n",
    "    framework_version=\"1.0\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c4.xlarge\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"Test Accuracy\", \"Regex\": \"Test Accuracy: ([0-9\\\\.]+)\"}\n",
    "    ],\n",
    "    hyperparameters={\n",
    "        \"input_features\": input_features,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"output_dim\": 1,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Set up the hyperparameter tuning job\n",
    "hyperparameter_tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_metric_name=\"Test Accuracy\",\n",
    "    objective_type=\"Maximize\",\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"Test Accuracy\", \"Regex\": \"Test Accuracy: ([0-9\\\\.]+)\"}\n",
    "    ],\n",
    "    max_jobs=50,\n",
    "    max_parallel_jobs=10,\n",
    "    hyperparameter_ranges={\n",
    "        \"num_layers\": IntegerParameter(1, 10),\n",
    "        \"hidden_dim\": IntegerParameter(1, 512),\n",
    "        \"dropout_rate\": ContinuousParameter(0, 0.2),\n",
    "        \"momentum\": ContinuousParameter(0.8, 1),\n",
    "        \"train_batch_size\": IntegerParameter(32, 500),\n",
    "        \"epochs\": IntegerParameter(1, 50),\n",
    "        \"lr\": ContinuousParameter(0.001, 0.2),\n",
    "    },\n",
    ")\n",
    "\n",
    "hyperparameter_tuner.fit(\n",
    "    {\"train\": preprocessed_training_data, \"test\": preprocessed_test_data}\n",
    ")\n",
    "hyperparameter_tuner.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get analysis on the tuning job including best hyperparameters\n",
    "tuning_analysis = (\n",
    "    hyperparameter_tuner.analytics()\n",
    "    .dataframe()\n",
    "    .sort_values(by=[\"TrainingStartTime\"], ascending=False, axis=0)\n",
    ")\n",
    "tuning_analysis[\"iteration\"] = tuning_analysis.index\n",
    "tuning_analysis.sort_values(\n",
    "    by=[\"FinalObjectiveValue\"], ascending=False, axis=0, inplace=True\n",
    ")\n",
    "\n",
    "tuning_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the value of hyperparameters over the tuning window\n",
    "plt_hyper.plot_hyperparams_over_search(\n",
    "    df=tuning_analysis,\n",
    "    hyperparams=[\n",
    "        \"num_layers\",\n",
    "        \"hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"momentum\",\n",
    "        \"lr\",\n",
    "        \"num_layers\",\n",
    "        \"train_batch_size\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the value of hyperparameters over the tuning window\n",
    "plt_hyper.plot_hyperparams_over_search(\n",
    "    df=tuning_analysis,\n",
    "    hyperparams=[\n",
    "        \"num_layers\",\n",
    "        \"hidden_dim\",\n",
    "        \"dropout_rate\",\n",
    "        \"momentum\",\n",
    "        \"lr\",\n",
    "        \"num_layers\",\n",
    "        \"train_batch_size\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-10 23:14:34 Starting - Preparing the instances for training\n",
      "2020-03-10 23:14:34 Downloading - Downloading input data\n",
      "2020-03-10 23:14:34 Training - Training image download completed. Training in progress.\n",
      "2020-03-10 23:14:34 Uploading - Uploading generated training model\n",
      "2020-03-10 23:14:34 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:18,190 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:18,191 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value Test Accuracy to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:18,193 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:18,205 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:19,632 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:19,894 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:19,894 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:19,894 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:19,894 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l4mmk4zn/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:21,523 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value Test Accuracy to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:21,525 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:21,537 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.pytorch.estimator\",\n",
      "        \"sagemaker_estimator_class_name\": \"PyTorch\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout_rate\": 0.18978101987321613,\n",
      "        \"lr\": 0.0019286030538385437,\n",
      "        \"input_features\": 70,\n",
      "        \"momentum\": 1.0,\n",
      "        \"train_batch_size\": 495,\n",
      "        \"hidden_dim\": 2,\n",
      "        \"test_batch_size\": 1131,\n",
      "        \"num_layers\": 7,\n",
      "        \"epochs\": 2,\n",
      "        \"output_dim\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-200310-2257-040-579ce0de\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-800613416076/sagemaker-pytorch-2020-03-10-22-57-42-378/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout_rate\":0.18978101987321613,\"epochs\":2,\"hidden_dim\":2,\"input_features\":70,\"lr\":0.0019286030538385437,\"momentum\":1.0,\"num_layers\":7,\"output_dim\":1,\"test_batch_size\":1131,\"train_batch_size\":495}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"PyTorch\",\"sagemaker_estimator_module\":\"sagemaker.pytorch.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-800613416076/sagemaker-pytorch-2020-03-10-22-57-42-378/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"PyTorch\",\"sagemaker_estimator_module\":\"sagemaker.pytorch.estimator\"},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout_rate\":0.18978101987321613,\"epochs\":2,\"hidden_dim\":2,\"input_features\":70,\"lr\":0.0019286030538385437,\"momentum\":1.0,\"num_layers\":7,\"output_dim\":1,\"test_batch_size\":1131,\"train_batch_size\":495},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-200310-2257-040-579ce0de\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-800613416076/sagemaker-pytorch-2020-03-10-22-57-42-378/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout_rate\",\"0.18978101987321613\",\"--epochs\",\"2\",\"--hidden_dim\",\"2\",\"--input_features\",\"70\",\"--lr\",\"0.0019286030538385437\",\"--momentum\",\"1.0\",\"--num_layers\",\"7\",\"--output_dim\",\"1\",\"--test_batch_size\",\"1131\",\"--train_batch_size\",\"495\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.18978101987321613\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0019286030538385437\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT_FEATURES=70\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=1.0\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=495\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=2\u001b[0m\n",
      "\u001b[34mSM_HP_TEST_BATCH_SIZE=1131\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LAYERS=7\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIM=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --dropout_rate 0.18978101987321613 --epochs 2 --hidden_dim 2 --input_features 70 --lr 0.0019286030538385437 --momentum 1.0 --num_layers 7 --output_dim 1 --test_batch_size 1131 --train_batch_size 495\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34mGet test data loader.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Train Loss: 0.715380155726483\u001b[0m\n",
      "\u001b[34mTest Accuracy: 0.506631299734748\u001b[0m\n",
      "\u001b[34mEpoch: 2, Train Loss: 0.7069937163277676\u001b[0m\n",
      "\u001b[34mTest Accuracy: 0.506631299734748\u001b[0m\n",
      "\u001b[34m2020-03-10 23:14:23,796 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 41\n",
      "Billable seconds: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [20] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [20] [INFO] Listening at: unix:/tmp/gunicorn.sock (20)\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [20] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[34m[2020-03-10 23:21:01 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-mm8s8rwi/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mLoading model.\u001b[0m\n",
      "\u001b[34mmodel_info: {'input_features': 70, 'hidden_dim': 2, 'output_dim': 1, 'momentum': 1.0, 'dropout_rate': 0.18978101987321613, 'num_layers': 7}\u001b[0m\n",
      "\u001b[34mDone loading model.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Mar/2020:23:21:28 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Mar/2020:23:21:28 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-h2uuuxyo/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\n",
      "  Found existing installation: train 1.0.0\n",
      "    Uninstalling train-1.0.0:\n",
      "      Successfully uninstalled train-1.0.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mLoading model.\u001b[0m\n",
      "\u001b[34mmodel_info: {'input_features': 70, 'hidden_dim': 2, 'output_dim': 1, 'momentum': 1.0, 'dropout_rate': 0.18978101987321613, 'num_layers': 7}\u001b[0m\n",
      "\u001b[34mDone loading model.\u001b[0m\n",
      "\u001b[34m2020-03-10 23:21:32,293 flask.app    ERROR    Exception on /invocations [POST]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_functions.py\", line 85, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_pytorch_container/serving.py\", line 48, in default_input_fn\n",
      "    np_array) if content_type in content_types.UTF8_TYPES else torch.from_numpy(np_array)\u001b[0m\n",
      "\u001b[34mTypeError: can't convert np.ndarray of type numpy.void. The only supported types are: double, float, float16, int64, int32, and uint8.\n",
      "\u001b[0m\n",
      "\u001b[34mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2311, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1834, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1737, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 36, in reraise\n",
      "    raise value\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1818, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_transformer.py\", line 171, in transform\n",
      "    result = self._transform_fn(self._model, request.content, request.content_type, request.accept)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_transformer.py\", line 197, in _default_transform_fn\n",
      "    data = self._input_fn(content, content_type)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_functions.py\", line 87, in wrapper\n",
      "    six.reraise(error_class, error_class(e), sys.exc_info()[2])\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 692, in reraise\n",
      "    raise value.with_traceback(tb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_containers/_functions.py\", line 85, in wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sagemaker_pytorch_container/serving.py\", line 48, in default_input_fn\n",
      "    np_array) if content_type in content_types.UTF8_TYPES else torch.from_numpy(np_array)\u001b[0m\n",
      "\u001b[34msagemaker_containers._errors.ClientError: can't convert np.ndarray of type numpy.void. The only supported types are: double, float, float16, int64, int32, and uint8.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [10/Mar/2020:23:21:32 +0000] \"POST /invocations HTTP/1.1\" 500 290 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:28.948:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.303:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: Bad HTTP status received from algorithm: 500\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.303:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: \u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.303:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: Message:\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.304:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.304:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: <title>500 Internal Server Error</title>\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.304:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: <h1>Internal Server Error</h1>\u001b[0m\n",
      "\u001b[32m2020-03-10T23:21:32.304:[sagemaker logs]: udacity-machine-learning-capstone-data/torch_valid_df.csv: <p>The server encountered an internal error and was unable to complete your request. Either the server is overloaded or there is an error in the application.</p>\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Transform job sagemaker-pytorch-200310-2257-040-579ce-2020-03-10-23-17-34-837: Failed. Reason: AlgorithmError: See job logs for more information",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-43442172f8d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msplit_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Line\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtorch_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;34m\"\"\"Placeholder docstring\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_last_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_transform_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/transformer.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_transform_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   3189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TransformJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2613\u001b[0m                 ),\n\u001b[1;32m   2614\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2615\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2616\u001b[0m             )\n\u001b[1;32m   2617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Transform job sagemaker-pytorch-200310-2257-040-579ce-2020-03-10-23-17-34-837: Failed. Reason: AlgorithmError: See job logs for more information"
     ]
    }
   ],
   "source": [
    "torch_attached = PyTorch.attach(hyperparameter_tuner.best_training_job())\n",
    "torch_transformer = torch_attached.transformer(\n",
    "    instance_count=1, instance_type=\"ml.m4.xlarge\"\n",
    ")\n",
    "\n",
    "valid_df = pd.read_csv(preprocessed_valid_data + \"/valid_df.csv\")\n",
    "y_valid = valid_df[['TARGET']]\n",
    "valid_df = valid_df.drop('TARGET', axis = 1)\n",
    "valid_df = valid_df.astype('float16')\n",
    "\n",
    "out_file=\"torch_valid_df.csv\"\n",
    "valid_df.to_csv('./{}'.format(out_file), header=None, index_label=None)\n",
    "bucket=\"udacity-machine-learning-capstone-data\"\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(out_file).upload_file(\n",
    "        \"./{}\".format(out_file)\n",
    "    )\n",
    "\n",
    "torch_transformer.transform(\n",
    "    \"s3://{}/{}\".format(bucket, out_file),\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\",\n",
    ")\n",
    "torch_transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the predictions from S3 and read to csv\n",
    "!aws s3 cp --recursive $torch_transformer.output_path $data_dir\n",
    "y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "\n",
    "# Create the classification report\n",
    "report_dict = classification_report(y_valid, y_pred, output_dict=True)\n",
    "report_dict[\"accuracy\"] = accuracy_score(y_valid, predictions)\n",
    "report_dict[\"roc_auc\"] = roc_auc_score(y_valid, predictions)\n",
    "\n",
    "print(\"Classification report:\\n{}\".format(report_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
